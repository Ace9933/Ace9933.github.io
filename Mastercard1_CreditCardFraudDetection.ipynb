{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ace9933/Ace9933.github.io/blob/main/Mastercard1_CreditCardFraudDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FSJkY5bEgD1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from geopy.distance import geodesic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF0tPpnSFtNl",
        "outputId": "eb183d79-2876-4b9b-d887-a901c1ae3020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/fraudTrain.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-65f201039d0d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/fraudTrain.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/fraudTrain.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/fraudTrain.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MoFkuOrFvGJ"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laYLa81woujU"
      },
      "source": [
        "## **Exploratory Data Analysis (EDA)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-JySb72ovKx"
      },
      "outputs": [],
      "source": [
        "print(df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2Nuh4cSoyMo"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx763PlnqHcC"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_fraudulent = df[df['is_fraud'] == 1]\n",
        "df_fraudulent.head(20)"
      ],
      "metadata": {
        "id": "VJG0J2P753cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID7aoqzTv1Yk"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=['Unnamed: 0'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fygYbJrswXeA"
      },
      "source": [
        "The 'Unnamed: 0' column consists of the row number of each credit card transaction entry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-x8_W5IsFab"
      },
      "outputs": [],
      "source": [
        "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "correlation_matrix = numeric_df.corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix of Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHKNji1-sTyx"
      },
      "outputs": [],
      "source": [
        "df['log_amt'] = np.log1p(df['amt'])\n",
        "sns.boxplot(x='is_fraud', y='log_amt', data=df)\n",
        "plt.title('Log Transaction Amount Distribution by Fraud Status')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fraudulent transactions tend to involve higher amounts when compared to non-fraudulent ones, which aligns with the earlier correlation matrix analysis showing a moderate positive correlation between transaction amount (amt) and fraud (is_fraud)."
      ],
      "metadata": {
        "id": "YCw8KsBAxoHK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcOzAV0ct6ar"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "features = ['amt', 'city_pop', 'lat', 'long', 'merch_lat', 'merch_long']\n",
        "for feature in features:\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.histplot(data=df, x=feature, hue='is_fraud', multiple='stack', kde=True)\n",
        "    plt.title(f'Distribution of {feature} by Fraud Status')\n",
        "    plt.show()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PPGWZp1ryesj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Cleaning**\n"
      ],
      "metadata": {
        "id": "sW8NzeRv37LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['cc_num', 'Unnamed', 'gender'], errors='ignore')"
      ],
      "metadata": {
        "id": "57zr4c2z3_RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "92vLpsbl4T-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no missing values"
      ],
      "metadata": {
        "id": "kb7fO7jo4gCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
        "df['hour'] = df['trans_date_trans_time'].dt.hour\n",
        "df['day_of_week'] = df['trans_date_trans_time'].dt.dayofweek\n",
        "df['month'] = df['trans_date_trans_time'].dt.month\n"
      ],
      "metadata": {
        "id": "WVzLROcb4cGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['unique_id'] = df['first'] + '_' + df['last'] + '_' + df['street']\n"
      ],
      "metadata": {
        "id": "8gNIQZOR7VSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "unique_id: Combines 'first', 'last', and 'street' to create a unique identifier for individuals.\n"
      ],
      "metadata": {
        "id": "CsOBe_3m9S7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['transaction_count'] = df.groupby('unique_id')['unique_id'].transform('count')\n"
      ],
      "metadata": {
        "id": "sbVPiMGu7cDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "transaction_count: Counts how many transactions are associated with each individual.\n"
      ],
      "metadata": {
        "id": "mCveCQs19YvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['fraudulent_transaction_count'] = df.groupby('unique_id')['is_fraud'].transform('sum')\n"
      ],
      "metadata": {
        "id": "NGMEmW3j7zf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fraudulent_transaction_count: Counts how many fraudulent transactions are associated with each individual."
      ],
      "metadata": {
        "id": "UGuoww789aaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['multiple_fraud_flag'] = df['fraudulent_transaction_count'] > 1\n"
      ],
      "metadata": {
        "id": "qqqNSyZx9KYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiple_fraud_flag: A binary feature to flag individuals with more than one fraudulent transaction."
      ],
      "metadata": {
        "id": "NTrxMiCG9hBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['dob'] = pd.to_datetime(df['dob'])\n",
        "df['age'] = df['trans_date_trans_time'].dt.year - df['dob'].dt.year\n"
      ],
      "metadata": {
        "id": "UFAX-_n09M73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we create an age column from the dob feature"
      ],
      "metadata": {
        "id": "-tsRYvYc_EtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns=['city', 'state', 'job'], drop_first=True)\n"
      ],
      "metadata": {
        "id": "3vAWIk799lXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['first', 'last', 'street', 'trans_num', 'dob'])\n"
      ],
      "metadata": {
        "id": "a5tRScS79plo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud_distribution = df['is_fraud'].value_counts(normalize=True) * 100\n",
        "print(fraud_distribution)\n"
      ],
      "metadata": {
        "id": "PkgWzRAe_Lxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values(by=['unique_id', 'trans_date_trans_time'])\n",
        "df['cumsum_amt'] = df.groupby('unique_id')['amt'].cumsum()\n",
        "df['prev_cumsum_amt'] = df.groupby('unique_id')['cumsum_amt'].shift(1)\n"
      ],
      "metadata": {
        "id": "WEtJgLBhTNxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorts the data by customer and transaction time to ensure calculations occur in the correct order.\n",
        "Calculates the running total of how much each customer has spent over time.\n",
        "Shifts this cumulative total to capture how much the customer had spent before the current transaction."
      ],
      "metadata": {
        "id": "PeRYBm_dV7-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['trans_7d_count'] = df.groupby('unique_id').cumcount() + 1\n",
        "df['prev_trans_count'] = df.groupby('unique_id')['trans_7d_count'].shift(1)\n",
        "df[['trans_date_trans_time', 'amt', 'trans_7d_count', 'prev_trans_count']].head()\n"
      ],
      "metadata": {
        "id": "DaZ-HpyoT4yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Created a running transaction count (trans_7d_count) for each customer.\n",
        "Shifted the transaction count by one to capture how many transactions occurred before the current transaction."
      ],
      "metadata": {
        "id": "Fd5OEUh6XtD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['spending_velocity'] = df['amt_7d_sum'] / df['prev_trans_count']\n",
        "df['spending_velocity'].fillna(0, inplace=True)\n",
        "df[['amt_7d_sum', 'prev_trans_count', 'spending_velocity']].head()\n"
      ],
      "metadata": {
        "id": "Zezy-_hOUYLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spending velocity (spending_velocity) measures the average amount spent per transaction over a recent time window (7 days in this case). It is a useful feature to detect abnormal spending behavior, which might indicate potential fraud."
      ],
      "metadata": {
        "id": "tEpAE2zlYCxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_distance(row):\n",
        "    customer_location = (row['lat'], row['long'])\n",
        "    merchant_location = (row['merch_lat'], row['merch_long'])\n",
        "    return geodesic(customer_location, merchant_location).kilometers\n",
        "df['distance'] = df.apply(calculate_distance, axis=1)\n",
        "df[['lat', 'long', 'merch_lat', 'merch_long', 'distance']].head()\n"
      ],
      "metadata": {
        "id": "3AlblcADVBBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We created a new feature that calculates the distance between the customer and the merchant for each transaction. Using the `geodesic()` function from the `geopy` library, we computed the distance in kilometers based on the latitude and longitude of both the customer and merchant. This was applied row-by-row to the DataFrame, and the resulting distances were stored in a new column, `distance`. This feature helps detect potentially fraudulent transactions that occur far from the customer's typical location."
      ],
      "metadata": {
        "id": "Tqc4qxbAY2Xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['fraud_7d_flag'] = df.groupby('unique_id')['is_fraud'].apply(\n",
        "    lambda x: x.rolling(window=7, min_periods=1).sum()\n",
        ").reset_index(level=0, drop=True)\n",
        "df['fraud_7d_flag'] = df['fraud_7d_flag'].apply(lambda x: 1 if x > 0 else 0)\n",
        "df[['trans_date_trans_time', 'is_fraud', 'fraud_7d_flag']].head()\n"
      ],
      "metadata": {
        "id": "DdSx9OhZVLO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we created a new feature, `fraud_7d_flag`, to track whether a customer has committed any fraudulent transactions in the past 7 days. First, we used a rolling window of 7 days within each customer group to sum the fraudulent transactions. Then, we converted this sum into a binary flag, where `1` indicates at least one fraud within the past 7 days and `0` indicates none. The resulting feature helps to identify customers with recent fraudulent activity, which can be useful for detecting suspicious patterns."
      ],
      "metadata": {
        "id": "vy7aaCicZKAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['zip'])\n"
      ],
      "metadata": {
        "id": "z4U-G5jUVSdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())\n",
        "df.dropna(subset=['prev_trans_count'], inplace=True)\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "0ZEajTQAZnL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.dropna(inplace=True)\n"
      ],
      "metadata": {
        "id": "RmQFLTwsfevk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.isnull().sum())\n",
        "X.dropna(inplace=True)\n"
      ],
      "metadata": {
        "id": "fzzhsVZgflYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = X.align(y, join='inner', axis=0)\n",
        "\n",
        "print(X.shape, y.shape)\n"
      ],
      "metadata": {
        "id": "YjH9n6GigIpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "print(\"Training set:\", X_train.shape, y_train.shape)\n",
        "print(\"Test set:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "id": "l7e35hSkg_ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for datetime columns\n",
        "datetime_cols = X_train.select_dtypes(include=['datetime', 'datetimetz']).columns\n",
        "print(f\"Datetime columns: {datetime_cols}\")\n"
      ],
      "metadata": {
        "id": "hEvhTMHIhbbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert datetime columns to Unix timestamp\n",
        "for col in datetime_cols:\n",
        "    X_train[col] = X_train[col].astype('int64') // 10**9  # Convert to Unix timestamp\n",
        "    X_test[col] = X_test[col].astype('int64') // 10**9  # Ensure the test set is also converted\n"
      ],
      "metadata": {
        "id": "H3ORVLmNhq35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop datetime columns if not needed\n",
        "X_train = X_train.drop(columns=datetime_cols, errors='ignore')\n",
        "X_test = X_test.drop(columns=datetime_cols, errors='ignore')\n"
      ],
      "metadata": {
        "id": "bH_JOruVmY2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vuVl5iqKmcN6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}